"""
åœºæ™¯æ¡ä»¶GameFormer (Scene-Conditioned GameFormer)
==============================================

ç›®æ ‡ï¼šåœ¨GameFormeråŸºç¡€ä¸Šæ·»åŠ è¯­ä¹‰æ¡ä»¶embeddingï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨åœºæ™¯è¯­ä¹‰ä¿¡æ¯

æ ¸å¿ƒæ”¹è¿›ï¼š
1. æ·»åŠ è¯­ä¹‰embeddingå±‚ï¼ˆscene_type, scene_subtype, keywordsï¼‰
2. å°†è¯­ä¹‰ç‰¹å¾èåˆåˆ°encoderè¾“å‡º
3. åœ¨å›°éš¾åœºæ™¯ï¼ˆintersection/cut_inï¼‰ä¸­æä¾›é¢å¤–æŒ‡å¯¼

è®­ç»ƒç­–ç•¥ï¼š
- ä½¿ç”¨LLMæ ‡æ³¨çš„è¯­ä¹‰æ ‡ç­¾ä½œä¸ºæ¡ä»¶
- åœ¨é•¿å°¾åœºæ™¯ä¸Šè¿‡é‡‡æ ·ï¼ˆcritical/highæ ·æœ¬ï¼‰
- è”åˆä¼˜åŒ–é¢„æµ‹ç²¾åº¦å’Œè¯­ä¹‰å¯¹é½
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from GameFormer.predictor import Encoder, Decoder, NeuralPlanner


class SemanticEmbedding(nn.Module):
    """
    è¯­ä¹‰æ¡ä»¶embeddingæ¨¡å—
    
    è¾“å…¥ï¼š
    - scene_type: åœºæ™¯ç±»å‹ç´¢å¼• [batch_size]
    - scene_keywords: å…³é”®è¯å¤šçƒ­ç¼–ç  [batch_size, vocab_size]
    
    è¾“å‡ºï¼š
    - semantic_embedding: [batch_size, embed_dim]
    """
    
    def __init__(self, vocab_size, embed_dim=256, dropout=0.1):
        super(SemanticEmbedding, self).__init__()
        
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        
        # åœºæ™¯ç±»å‹embeddingï¼ˆç±»åˆ«å˜é‡ï¼‰
        # é¢„å®šä¹‰çš„åœºæ™¯ç±»å‹ï¼ˆä¸LLMæ ‡æ³¨å¯¹é½ï¼‰
        self.scene_types = [
            'intersection', 'cut_in', 'merging', 'yielding', 
            'occlusion', 'congestion', 'high_speed', 'other'
        ]
        self.num_scene_types = len(self.scene_types)
        self.scene_type_embedding = nn.Embedding(self.num_scene_types, embed_dim // 2)
        
        # å…³é”®è¯embeddingï¼ˆå¤šçƒ­ç¼–ç ï¼‰
        # ä½¿ç”¨çº¿æ€§å±‚å°†å…³é”®è¯å¤šçƒ­å‘é‡æ˜ å°„åˆ°embeddingç©ºé—´
        self.keyword_embedding = nn.Sequential(
            nn.Linear(vocab_size, embed_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(embed_dim, embed_dim // 2)
        )
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(embed_dim, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
    
    def forward(self, scene_type_ids, keyword_vectors):
        """
        Args:
            scene_type_ids: [batch_size] åœºæ™¯ç±»å‹ç´¢å¼•
            keyword_vectors: [batch_size, vocab_size] å…³é”®è¯å¤šçƒ­å‘é‡
        
        Returns:
            semantic_embedding: [batch_size, embed_dim]
        """
        # åœºæ™¯ç±»å‹embedding
        scene_type_emb = self.scene_type_embedding(scene_type_ids)  # [B, embed_dim//2]
        
        # å…³é”®è¯embedding
        keyword_emb = self.keyword_embedding(keyword_vectors)  # [B, embed_dim//2]
        
        # æ‹¼æ¥å¹¶èåˆ
        combined = torch.cat([scene_type_emb, keyword_emb], dim=-1)  # [B, embed_dim]
        semantic_embedding = self.fusion(combined)
        
        return semantic_embedding


class SceneConditionedEncoder(nn.Module):
    """
    åœºæ™¯æ¡ä»¶ç¼–ç å™¨
    
    åœ¨åŸå§‹EncoderåŸºç¡€ä¸Šèåˆè¯­ä¹‰æ¡ä»¶
    """
    
    def __init__(self, vocab_size, dim=256, layers=6, heads=8, dropout=0.1):
        super(SceneConditionedEncoder, self).__init__()
        
        # åŸå§‹GameFormerç¼–ç å™¨
        self.base_encoder = Encoder(dim, layers, heads, dropout)
        
        # è¯­ä¹‰embedding
        self.semantic_embedding = SemanticEmbedding(vocab_size, dim, dropout)
        
        # æ¡ä»¶èåˆå±‚ï¼ˆå°†è¯­ä¹‰ç‰¹å¾èåˆåˆ°ç¼–ç ä¸­ï¼‰
        self.condition_fusion = nn.MultiheadAttention(
            embed_dim=dim,
            num_heads=heads,
            dropout=dropout,
            batch_first=True
        )
        
        self.condition_norm = nn.LayerNorm(dim)
    
    def forward(self, inputs, scene_type_ids, keyword_vectors):
        """
        Args:
            inputs: åŸå§‹è¾“å…¥ï¼ˆä¸GameFormerç›¸åŒï¼‰
            scene_type_ids: [batch_size] åœºæ™¯ç±»å‹ç´¢å¼•
            keyword_vectors: [batch_size, vocab_size] å…³é”®è¯å¤šçƒ­å‘é‡
        
        Returns:
            encoder_outputs: ç¼–ç è¾“å‡ºï¼ˆä¸GameFormeræ ¼å¼ç›¸åŒï¼Œä½†èåˆäº†è¯­ä¹‰ä¿¡æ¯ï¼‰
        """
        # 1. åŸºç¡€ç¼–ç 
        encoder_outputs = self.base_encoder(inputs)
        encoding = encoder_outputs['encoding']  # [B, N, dim]
        mask = encoder_outputs['mask']  # [B, N]
        
        # 2. è¯­ä¹‰embedding
        semantic_emb = self.semantic_embedding(scene_type_ids, keyword_vectors)  # [B, dim]
        semantic_emb = semantic_emb.unsqueeze(1)  # [B, 1, dim]
        
        # 3. æ¡ä»¶èåˆï¼ˆä½¿ç”¨cross-attentionï¼‰
        # å°†è¯­ä¹‰ä½œä¸ºqueryï¼Œç¼–ç ä½œä¸ºkey/value
        conditioned_encoding, _ = self.condition_fusion(
            query=semantic_emb.expand(-1, encoding.shape[1], -1),  # [B, N, dim]
            key=encoding,
            value=encoding,
            key_padding_mask=mask
        )
        
        # æ®‹å·®è¿æ¥ + LayerNorm
        encoding = self.condition_norm(encoding + conditioned_encoding)
        
        # æ›´æ–°è¾“å‡º
        encoder_outputs['encoding'] = encoding
        encoder_outputs['semantic_embedding'] = semantic_emb.squeeze(1)  # [B, dim]
        
        return encoder_outputs


class SceneConditionedGameFormer(nn.Module):
    """
    åœºæ™¯æ¡ä»¶GameFormer
    
    æ¶æ„ï¼š
    1. SceneConditionedEncoderï¼šèåˆè¯­ä¹‰æ¡ä»¶
    2. Decoderï¼šä¸åŸå§‹GameFormerç›¸åŒ
    3. NeuralPlannerï¼šä¸åŸå§‹GameFormerç›¸åŒ
    """
    
    def __init__(
        self,
        vocab_size,
        encoder_layers=6,
        decoder_levels=3,
        modalities=6,
        neighbors=10
    ):
        super(SceneConditionedGameFormer, self).__init__()
        
        self.vocab_size = vocab_size
        
        # åœºæ™¯æ¡ä»¶ç¼–ç å™¨
        self.encoder = SceneConditionedEncoder(
            vocab_size=vocab_size,
            layers=encoder_layers
        )
        
        # ä¸åŸå§‹GameFormerå…±äº«çš„decoderå’Œplanner
        self.decoder = Decoder(neighbors, modalities, decoder_levels)
        self.planner = NeuralPlanner()
    
    def forward(self, inputs, scene_type_ids=None, keyword_vectors=None):
        """
        Args:
            inputs: åŸå§‹è¾“å…¥ï¼ˆä¸GameFormerç›¸åŒï¼‰
            scene_type_ids: [batch_size] åœºæ™¯ç±»å‹ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            keyword_vectors: [batch_size, vocab_size] å…³é”®è¯å¤šçƒ­å‘é‡ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            decoder_outputs: é¢„æµ‹è¾“å‡º
            ego_plan: è‡ªè½¦è½¨è¿¹
        """
        # å¦‚æœæœªæä¾›è¯­ä¹‰æ¡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆ'other'åœºæ™¯ï¼Œå…¨é›¶å…³é”®è¯ï¼‰
        if scene_type_ids is None:
            batch_size = inputs['ego_agent_past'].shape[0]
            scene_type_ids = torch.full(
                (batch_size,), 
                7,  # 'other' çš„ç´¢å¼•
                dtype=torch.long,
                device=inputs['ego_agent_past'].device
            )
        
        if keyword_vectors is None:
            batch_size = inputs['ego_agent_past'].shape[0]
            keyword_vectors = torch.zeros(
                (batch_size, self.vocab_size),
                dtype=torch.float32,
                device=inputs['ego_agent_past'].device
            )
        
        # ç¼–ç ï¼ˆèåˆè¯­ä¹‰æ¡ä»¶ï¼‰
        encoder_outputs = self.encoder(inputs, scene_type_ids, keyword_vectors)
        
        # è§£ç ï¼ˆä¸åŸå§‹GameFormerç›¸åŒï¼‰
        route_lanes = encoder_outputs['route_lanes']
        initial_state = encoder_outputs['actors'][:, 0, -1]
        decoder_outputs, env_encoding = self.decoder(encoder_outputs)
        ego_plan = self.planner(env_encoding, route_lanes, initial_state)
        
        return decoder_outputs, ego_plan
    
    @staticmethod
    def from_pretrained(pretrained_path, vocab_size, **kwargs):
        """
        ä»é¢„è®­ç»ƒçš„GameFormeråˆå§‹åŒ–
        
        ç­–ç•¥ï¼š
        1. åŠ è½½GameFormeræƒé‡åˆ°encoder.base_encoder
        2. éšæœºåˆå§‹åŒ–semantic_embeddingå’Œcondition_fusion
        3. å†»ç»“éƒ¨åˆ†å±‚ï¼ˆå¯é€‰ï¼‰
        
        Args:
            pretrained_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            vocab_size: è¯­ä¹‰è¯è¡¨å¤§å°
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            model: åˆå§‹åŒ–å¥½çš„æ¨¡å‹
        """
        # åˆ›å»ºæ¨¡å‹
        model = SceneConditionedGameFormer(vocab_size, **kwargs)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        print(f"Loading pretrained GameFormer from {pretrained_path}...")
        checkpoint = torch.load(pretrained_path, map_location='cpu')
        
        # æå–GameFormerçš„æƒé‡
        gameformer_state_dict = checkpoint.get('model', checkpoint)
        
        # åŠ è½½åˆ°base_encoder, decoder, planner
        model_state_dict = model.state_dict()
        pretrained_dict = {}
        
        for k, v in gameformer_state_dict.items():
            # encoder.* -> encoder.base_encoder.* (only replace the first prefix)
            if k.startswith('encoder.'):
                new_k = k.replace('encoder.', 'encoder.base_encoder.', 1)
                if new_k in model_state_dict:
                    pretrained_dict[new_k] = v
            # decoder.*, planner.* ç›´æ¥å¤åˆ¶
            elif k.startswith('decoder.') or k.startswith('planner.'):
                if k in model_state_dict:
                    pretrained_dict[k] = v
        
        print(f"Loaded {len(pretrained_dict)}/{len(model_state_dict)} parameters from pretrained model")
        
        # æ›´æ–°æ¨¡å‹æƒé‡
        model_state_dict.update(pretrained_dict)
        model.load_state_dict(model_state_dict)
        
        print("âœ… Successfully initialized from pretrained GameFormer")
        print(f"   - Base encoder: {len([k for k in pretrained_dict if 'base_encoder' in k])} params")
        print(f"   - Decoder: {len([k for k in pretrained_dict if 'decoder' in k])} params")
        print(f"   - Planner: {len([k for k in pretrained_dict if 'planner' in k])} params")
        print(f"   - Semantic (random init): {len([k for k in model_state_dict if 'semantic' in k or 'condition' in k])} params")
        
        return model
    
    def freeze_base_encoder(self):
        """å†»ç»“åŸºç¡€ç¼–ç å™¨ï¼ˆä»…è®­ç»ƒè¯­ä¹‰éƒ¨åˆ†ï¼‰"""
        for param in self.encoder.base_encoder.parameters():
            param.requires_grad = False
        print("âœ… Froze base encoder parameters")
    
    def unfreeze_all(self):
        """è§£å†»æ‰€æœ‰å‚æ•°"""
        for param in self.parameters():
            param.requires_grad = True
        print("âœ… Unfroze all parameters")


# ============================================================================
# è¾…åŠ©å‡½æ•°ï¼šåœºæ™¯ç±»å‹å’Œå…³é”®è¯è½¬æ¢
# ============================================================================

def get_scene_type_mapping():
    """è·å–åœºæ™¯ç±»å‹æ˜ å°„"""
    scene_types = [
        'intersection', 'cut_in', 'merging', 'yielding', 
        'occlusion', 'congestion', 'high_speed', 'other'
    ]
    return {s: i for i, s in enumerate(scene_types)}


def encode_scene_semantic(labels, vocab_dict):
    """
    å°†LLMæ ‡æ³¨è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥
    
    Args:
        labels: LLMæ ‡æ³¨ç»“æœåˆ—è¡¨ï¼ˆå­—å…¸ï¼‰
        vocab_dict: è¯­ä¹‰è¯è¡¨ {keyword: id}
    
    Returns:
        scene_type_ids: [N] åœºæ™¯ç±»å‹ç´¢å¼•
        keyword_vectors: [N, vocab_size] å…³é”®è¯å¤šçƒ­å‘é‡
    """
    scene_type_mapping = get_scene_type_mapping()
    vocab_size = len(vocab_dict)
    
    scene_type_ids = []
    keyword_vectors = []
    
    for label in labels:
        # åœºæ™¯ç±»å‹
        scene_type = label.get('scene_type', 'other')
        scene_type_id = scene_type_mapping.get(scene_type, 7)  # é»˜è®¤'other'=7
        scene_type_ids.append(scene_type_id)
        
        # å…³é”®è¯å¤šçƒ­å‘é‡
        keywords = label.get('semantic_keywords', [])
        keyword_vec = torch.zeros(vocab_size)
        for kw in keywords:
            if kw in vocab_dict:
                keyword_vec[vocab_dict[kw]] = 1.0
        keyword_vectors.append(keyword_vec)
    
    scene_type_ids = torch.tensor(scene_type_ids, dtype=torch.long)
    keyword_vectors = torch.stack(keyword_vectors)
    
    return scene_type_ids, keyword_vectors


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    import json
    
    print("="*80)
    print("Testing Scene-Conditioned GameFormer")
    print("="*80)
    
    # 1. åŠ è½½è¯­ä¹‰è¯è¡¨
    vocab_path = './eval_out/clusters/semantic_vocab.json'
    if Path(vocab_path).exists():
        with open(vocab_path, 'r') as f:
            vocab_data = json.load(f)
            vocab_size = vocab_data['vocab_size']
            vocab_dict = vocab_data['keyword_to_id']
        print(f"\nâœ… Loaded semantic vocabulary: {vocab_size} keywords")
    else:
        print(f"\nâš ï¸  Vocabulary not found, using dummy vocab_size=100")
        vocab_size = 100
        vocab_dict = {}
    
    # 2. åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  Creating Scene-Conditioned GameFormer...")
    model = SceneConditionedGameFormer(
        vocab_size=vocab_size,
        encoder_layers=6,
        decoder_levels=3,
        modalities=6,
        neighbors=10
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"âœ… Model created")
    print(f"   Total parameters: {total_params:,}")
    print(f"   Trainable parameters: {trainable_params:,}")
    
    # 3. æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\nğŸ§ª Testing forward pass...")
    
    batch_size = 2
    
    # æ„é€ dummyè¾“å…¥
    dummy_inputs = {
        'ego_agent_past': torch.randn(batch_size, 21, 7),
        'neighbor_agents_past': torch.randn(batch_size, 10, 21, 11),
        'map_lanes': torch.randn(batch_size, 100, 50, 7),
        'map_crosswalks': torch.randn(batch_size, 50, 30, 3),
        'route_lanes': torch.randn(batch_size, 10, 50, 3)
    }
    
    # åœºæ™¯æ¡ä»¶ï¼ˆæ¨¡æ‹ŸLLMæ ‡æ³¨ï¼‰
    scene_type_ids = torch.tensor([0, 1])  # intersection, cut_in
    keyword_vectors = torch.randn(batch_size, vocab_size).sigmoid()  # éšæœºå…³é”®è¯
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        decoder_outputs, ego_plan = model(
            dummy_inputs,
            scene_type_ids=scene_type_ids,
            keyword_vectors=keyword_vectors
        )
    
    print(f"âœ… Forward pass successful")
    print(f"   Ego plan shape: {ego_plan.shape}")  # [B, 80, 3]
    print(f"   Decoder outputs keys: {list(decoder_outputs.keys())}")
    
    # 4. æµ‹è¯•ä»é¢„è®­ç»ƒåŠ è½½
    pretrained_path = './training_log/Exp1/model_epoch_17_valADE_1.97.pth'
    from pathlib import Path
    if Path(pretrained_path).exists():
        print(f"\nğŸ”„ Testing loading from pretrained...")
        model_pretrained = SceneConditionedGameFormer.from_pretrained(
            pretrained_path,
            vocab_size=vocab_size
        )
        print(f"âœ… Pretrained loading successful")
    else:
        print(f"\nâš ï¸  Pretrained model not found at {pretrained_path}")
    
    print("\n" + "="*80)
    print("âœ… All tests passed!")
    print("="*80)
